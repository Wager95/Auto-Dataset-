---
title: "Data Science in R: Analysis of Vehicles"
author: "William Wager Johnsen"
date: "26/12/2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objective
* Identifying whether a vehicle has relatively environmental good milage.
* Identify which characteristics that has a statistical significance on the milage per gallon. 

## Description of data
* Dataset: Auto-Mpg Data.
* Origin: This dataset was taken from the StatLib library, which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition.
* Date: July 7, 1993.
* Date of observations: 1970 to 1982.
* Assumption: A vehicle has a good consumption if it can do 23 miles per gallon of gasoline.

## Process of Analysis
1. Clean dataset.
    + Model year has been changed to "0" for year 1970, "1" for 1971, and so on.
    + Displacement was changed to the total volume of the engine(cylinder times original displacement numbers).
2. Create a logistic regression(Binomial Model) model in order to identify which of the characteristics that might be statistically significant. 
3. Create a decision tree with the same characteristics as the logistic model.
4. Compare the two models.
5. Conclusion


```{r dataset, echo=FALSE, warning=FALSE, message=FALSE}
library(readr)
library(rpart)
library(ROCR)
library(gplots)
library(rpart.plot)
library(stringr)

autodf <- read.csv("~/Hult International Business School/DS_R/Auto/auto_mpg.csv", header = TRUE)

#Rename some  col names
colnames(autodf)[1] <- "mpg"
colnames(autodf)[8] <- "origin"


#Replace NA with (blank)
autodf$mpg <- gsub("NA", "", autodf$mpg)


#Removing missing values
autodf <- na.omit(autodf)

#Calculating total displacement(volume in CC) and adding litres of engine
autodf$displacement <- autodf$cylinders * autodf$displacement

############################################################################
########################DONT RUN THIS MORE THAN ONCE########################
############################################################################
# Converting to litres                                                     #
autodf$litres <- autodf$displacement / 1000                                #
#Moving litres to index 4 - DONT RUN THIS MORE THAN ONCE                   #
autodf <- autodf[, colnames(autodf)[c(1:3, 10, 4:9)]]                      #
                                                                           #
#Convert weight from pound to kg - DONT RUN THIS MORE THAN ONCE            #
#autodf$weight <- autodf$weight * 0.45359237                               #
                                                                           #
#Change year 1970 to year 0 - DONT RUN THIS MORE THAN ONCE                 #
autodf$model_year <- autodf$model_year - 70                                #
############################################################################
############################################################################
############################################################################

# Replacing mpg with 1 or 0 - Above 23 is 1
autodf$mpg_good <- c()

for(i in 1:nrow(autodf)){
  if(autodf$mpg[i] >= 23){
    autodf$mpg_good[i] <- 1
  }
  else if(autodf$mpg[i] < 23){
    autodf$mpg_good[i] <- 0
  }
  else{
    print("Error")
  }
}

mpg_logit <- glm(mpg_good ~  horsepower + weight + model_year + origin, data = autodf, family = "binomial")
summary(mpg_logit)
```

### Logistical business insights
* First off I started out with all the different variables that the dataset provided: Number of cylinders, displacement(size of each cylinder), horsepower, weight, acceleration, model year. 
    + I kept trimming the model until all the model are statistically significant (except origin).
* Based on the numbers above, we can conclude the following:
    + If the number of horsepowers increases by 1, the probability of the car being environmental friendly decreases by 4.4 percent.
    + If the weight of the car increases by one pound, the probability of the vehicle being environmental friendly decreases by 0.43 percent.
    + The newer the car, the more environmental friendly. Increasing the model year by 1 will increase the probability of the car being environmental friendly by 53.6 percent.
    + It also looks like the European and Asian cars tends to be more environmental friendly than the American cars.

#### Now to the decision tree

```{r tree, echo=FALSE}
mpg_tree <- rpart(mpg_good ~  horsepower + weight + model_year + origin, data = autodf, method="class", cp = 0.01)
rpart.plot::rpart.plot(mpg_tree, type = 1, extra=1, box.palette =c("pink", "green"), branch.lty=3, shadow.col = "gray")
```

### Decision tree insight
* As mentioned earlier, I am using the same characteristics from the logistical regression.
* Here you are provided some examples in order to make it easier to read the tree: 
    + A car which weights more or equal to 2,765 pounds which was created before 1980 tends to be less environmental friendly (172 bad vs 8 good).
    + A car which weights more or equal to 2,765 pounds which was created after 1980 tends to be more environmental friendly (5 bad vs 16 good).
    + A car which weights less than 2,765 pounds which was created after 1974 tends to be more environmental friendly (3 bad vs 141 good).
    + A car which weights less than 2,279 pounds which was created before 1974, tends to be more environmental friendly (2 bad vs 24 good).
    
#### Let's compare the two models in regards of performance.

```{r compare, echo=FALSE}
pred_tree <- predict(mpg_tree, autodf, type = "prob")
pred_logit <- predict(mpg_logit, autodf, type = "response") # Predict probability of 1

pred_val_t <- prediction(pred_tree[,2], autodf$mpg_good)
pred_val_logi <- prediction(pred_logit, autodf$mpg_good)

perf_t <- performance(pred_val_t, "tpr", "fpr")
perf_logi <- performance(pred_val_logi, "tpr", "fpr")

plot(perf_t, lwd=2,col = "black")
plot(perf_logi, lwd=3,col = "red", add= TRUE)
legend("bottomright", c("Tree", "Logistic"), fill=c("black", "red"))

```

### Performance comparison
* Red line represents the logistic regression. The black line represents the decision tree.
* Both the model seem to be very similar, and there is hard to tell if one of them is stronger than the other one unless we look at some specific values (for example illustrated in the top left corner where the black graph is above the red).

## Conclusion
To conclude, you can see that the logistical regression model takes more numbers into account; horsepower, weight, model year and origin, whereas the tree only looks into weight, model year (and one branch of origin). Both of the models provide us the understanding that weight and which year the car was manufactured has a high impact on the mileage per gallon. Year makes a lot of sense after doing some more research, since in 1975 the Congress passed a new law in order to increase fuel effiency. For further information on this, you are able to follow the follwing link: 
[Driving to 54.5 MPG](https://www.pewtrusts.org/en/research-and-analysis/fact-sheets/2011/04/20/driving-to-545-mpg-the-history-of-fuel-economy)
